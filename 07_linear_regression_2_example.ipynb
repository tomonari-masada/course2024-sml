{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-sml/blob/main/07_linear_regression_2_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy8AYW1oaHQi"
      },
      "source": [
        "# 課題\n",
        "* solubilityデータセットの、上で作った検証データに対して、できるだけ予測性能の良いモデルを見つけよう\n",
        "  * Ridge回帰やLassoを使ってもいいです。\n",
        "  * 特徴量はどのように加工してもいいです。（上では2値変数にPCAを使った。）\n",
        "* 検証データを使って見つけた最も良いモデルを、最後に一回、テストデータで評価してみよう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAs8TdF-Ly5J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "rng = np.random.RandomState(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHmuTZD1L5ka"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/data/'\n",
        "\n",
        "X = pd.read_csv(PATH + 'solTrainX.csv')\n",
        "y = pd.read_csv(PATH + 'solTrainY.csv')['x']\n",
        "\n",
        "X_test = pd.read_csv(PATH + 'solTestX.csv')\n",
        "y_test = pd.read_csv(PATH + 'solTestY.csv')['x']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJxFDaWRRh7S"
      },
      "outputs": [],
      "source": [
        "continuous = [s for s in X.columns if s[:3] in ['Num', 'Hyd', 'Mol', 'Sur']]\n",
        "print(len(continuous), 'continuous features')\n",
        "print(continuous)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9ts2bVrDA1B"
      },
      "outputs": [],
      "source": [
        "binary = X.columns[X.columns.str.startswith('FP')]\n",
        "print(len(binary), 'binary features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl72H7ak8ux3"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6SbbAdz8X3Q"
      },
      "outputs": [],
      "source": [
        "X[continuous].hist(bins=50, figsize=(12, 12));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S451HjBdth0f"
      },
      "source": [
        "* 最小値の頻度が突出して高いfeatureがいくつかある。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGIDsmxcth0f"
      },
      "outputs": [],
      "source": [
        "for feature in ['SurfaceArea1', 'SurfaceArea2', 'NumNitrogen', 'NumSulfer', 'NumChlorine', 'NumHalogen']:\n",
        "    print(feature, (X[feature].min() == X[feature]).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc7pdJ9B-YJI"
      },
      "source": [
        "* 新たなbinary featureを追加する。\n",
        "  * 最小値を取るときは1、そうでなければ0。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKsGU5HH7vRR"
      },
      "outputs": [],
      "source": [
        "for feature in ['SurfaceArea1', 'SurfaceArea2', 'NumNitrogen', 'NumSulfer', 'NumChlorine', 'NumHalogen']:\n",
        "    X_min = X[feature].min()\n",
        "    X[f\"FP_{feature}\"] = (X_min == X[feature]) * 1\n",
        "    X_test[f\"FP_{feature}\"] = (X_min == X_test[feature]) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrPWkm8d7_7V"
      },
      "outputs": [],
      "source": [
        "binary = X.columns[X.columns.str.startswith('FP')]\n",
        "print(len(binary), 'binary features')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oDWsk9Pth0f"
      },
      "source": [
        "## 交差検証の準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll15MGGhA8n2"
      },
      "outputs": [],
      "source": [
        "kfold_split = list(\n",
        "    KFold(n_splits=10, shuffle=True, random_state=rng).split(X)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZdeIG7hth0g"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_n_components = None\n",
        "for n_components in 0.94 + 0.01 * np.arange(5):\n",
        "  pca = PCA(n_components=n_components, random_state=rng)\n",
        "  reg = LinearRegression()\n",
        "\n",
        "  rmse = []\n",
        "  for train_index, val_index in kfold_split:\n",
        "    X_train, y_train = X.iloc[train_index], y[train_index]\n",
        "    X_valid, y_valid = X.iloc[val_index], y[val_index]\n",
        "\n",
        "    X_train_binary = pca.fit_transform(poly.fit_transform(X_train[binary]))\n",
        "    X_train_continuous = scaler.fit_transform(X_train[continuous])\n",
        "    X_train_embedded = np.concatenate([X_train_binary, X_train_continuous], 1)\n",
        "\n",
        "    X_valid_binary = pca.transform(poly.transform(X_valid[binary]))\n",
        "    X_valid_continuous = scaler.transform(X_valid[continuous])\n",
        "    X_valid_embedded = np.concatenate([X_valid_binary, X_valid_continuous], 1)\n",
        "\n",
        "    reg.fit(X_train_embedded, y_train)\n",
        "    y_valid_pred = reg.predict(X_valid_embedded)\n",
        "    rmse.append(mean_squared_error(y_valid, y_valid_pred, squared=False))\n",
        "\n",
        "  rmse = np.array(rmse)\n",
        "  print(f\"PCA {n_components:.2f} | \", end=\"\")\n",
        "  print(f\"max RMSE {rmse.max():.3f} | avg RMSE {rmse.mean():.3f}\")\n",
        "  if rmse.mean() < best_rmse:\n",
        "    best_rmse = rmse.mean()\n",
        "    best_n_components = n_components\n",
        "print(f\"best rmse {best_rmse:.3f} | n_components={best_n_components}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwfrLojscUyC"
      },
      "source": [
        "## Ridge回帰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx4_obDg5CXg"
      },
      "outputs": [],
      "source": [
        "poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_n_components = None\n",
        "best_alpha = None\n",
        "for n_components in 0.94 + 0.01 * np.arange(4):\n",
        "  pca = PCA(n_components=n_components, random_state=rng)\n",
        "\n",
        "  for alpha in 10.0 ** np.arange(-5, 0):\n",
        "    reg = Ridge(alpha=alpha, random_state=rng)\n",
        "\n",
        "    rmse = []\n",
        "    for train_index, val_index in kfold_split:\n",
        "      X_train, y_train = X.iloc[train_index], y[train_index]\n",
        "      X_valid, y_valid = X.iloc[val_index], y[val_index]\n",
        "\n",
        "      X_train_binary = pca.fit_transform(poly.fit_transform(X_train[binary]))\n",
        "      X_train_continuous = scaler.fit_transform(X_train[continuous])\n",
        "      X_train_embedded = np.concatenate([X_train_binary, X_train_continuous], 1)\n",
        "\n",
        "      X_valid_binary = pca.transform(poly.transform(X_valid[binary]))\n",
        "      X_valid_continuous = scaler.transform(X_valid[continuous])\n",
        "      X_valid_embedded = np.concatenate([X_valid_binary, X_valid_continuous], 1)\n",
        "\n",
        "      reg.fit(X_train_embedded, y_train)\n",
        "      y_valid_pred = reg.predict(X_valid_embedded)\n",
        "      rmse.append(mean_squared_error(y_valid, y_valid_pred, squared=False))\n",
        "\n",
        "    rmse = np.array(rmse)\n",
        "    print(f\"PCA {n_components:.2f} | alpha {alpha:.1e} | \", end=\"\")\n",
        "    print(f\"max RMSE {rmse.max():.3f} | avg RMSE {rmse.mean():.3f}\")\n",
        "    if rmse.mean() < best_rmse:\n",
        "      best_rmse = rmse.mean()\n",
        "      best_n_components = n_components\n",
        "      best_alpha = alpha\n",
        "\n",
        "  print('-'*40)\n",
        "print(f\"best rmse {best_rmse:.3f} | \", end=\"\")\n",
        "print(f\"n_components={best_n_components} | alpha={best_alpha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## テストセットで評価"
      ],
      "metadata": {
        "id": "EMp6TOUeuZRR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmqZu7AfJ4Q3"
      },
      "outputs": [],
      "source": [
        "n_components = best_n_components\n",
        "alpha = best_alpha\n",
        "\n",
        "pca = PCA(n_components=n_components, random_state=rng)\n",
        "poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_binary = pca.fit_transform(poly.fit_transform(X[binary]))\n",
        "X_continuous = scaler.fit_transform(X[continuous])\n",
        "X_embedded = np.concatenate([X_binary, X_continuous], 1)\n",
        "\n",
        "reg = Ridge(alpha=alpha, random_state=rng)\n",
        "reg.fit(X_embedded, y)\n",
        "\n",
        "X_test_binary = pca.transform(poly.transform(X_test[binary]))\n",
        "X_test_continuous = scaler.transform(X_test[continuous])\n",
        "X_test_embedded = np.concatenate([X_test_binary, X_test_continuous], 1)\n",
        "y_test_pred = reg.predict(X_test_embedded)\n",
        "print(f'test RMSE {mean_squared_error(y_test, y_test_pred, squared=False):.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}